<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    <link rel="stylesheet" href="css/style.css">

    <link href="https://fonts.googleapis.com/css?family=Cabin:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css" integrity="sha384-5sAR7xN1Nv6T6+dT2mhtzEpVJvfS3NScPQTrOxhwjIuvcA67KV2R5Jz6kr4abQsz" crossorigin="anonymous">

    <title>Good News Project</title>
  </head>
  <body>
    <div class="container-fluid project-header" id="good-news-project-header">
        <div class="row project-title">
            <h1>Good News</h1>
            <p><span title="Date">ðŸ“…</span> April 2018 &dash; Current</p>
            <p><span title="Built With">ðŸ”¨</span> C# | Python</p>
            <p><span title="Tools Used">ðŸ”§</span> .NET Core | Azure Functions | <a href="https://orange.biolab.si/" target="_blank">Orange</a></p>
            <p><span title="Link">ðŸ”— </span><a href="http://goodnws.azurewebsites.net/" target="_blank">Live</a> | <a href="https://github.com/Poc275/GoodNews" target="_blank"> GitHub</a></p>
            <p><span title="Background image by">ðŸ“·</span> (Background image by <a href="https://unsplash.com/@brandenharvey" target="_blank">Branden Harvey on Unsplash</a>)</p>
        </div>
    </div>

    <div class="container">
        <div class="row">
            <div class="col-md-6">
                <p>This project came about as part of a part-time MSc in Data Science I was undertaking at Aston University. This was a sponsored 
                    programme through my workplace that offered the chance to study Data Science modules part-time at your own pace with a chance to 
                    complete an MSc if enough modules were completed. The module in question was &lsquo;Understanding Data&rsquo; which was an introductory module 
                    aimed to convey a high level of understanding of the data analytics process. The final assessment was to use the techniques 
                    described in the module to solve a business problem of my own choosing.</p>

                <h2>The problem</h2>
                <p>The world of online news is getting a lot of attention. Recent political unrest has been blamed on the rise of fake news and 
                    social media companies not taking more care about the stories which are disseminated on their platforms. This has led to a 
                    situation where the very nature of news reporting has come under attack. I wondered if it was possible to create a news site 
                    that only reported on good news to try and restore the balance? This begs the question, &ldquo;Can news be separated into good news 
                    and bad news?&rdquo; With many people feeling tired of the barrage of negativity put forth by the mainstream media, coupled with 
                    a rising distrust, this could help restore peopleâ€™s faith in news reporting by informing them that it is not good news that is in 
                    short supply, it is good news reporting.</p>

                <p>Therefore, the objective of the analysis was to investigate whether news can be categorised into good and bad to decide whether a 
                    good news site is viable. The first question was to define what is meant by good news and bad news:</p>
                
                <ul>
                    <li>Good News: A news story without the negativity that seems to pervade the news today. This could be any positive news story 
                        such as an act of human kindness, a scientific breakthrough, a good policy decision or just something light hearted.</li>
                    <li>Bad News: This category is basically any other news story. One of the assumptions made about this analysis is that the 
                        overwhelming majority of news today is negative, the old adage &ldquo;if it bleeds, it leads&rdquo; seemingly the modus 
                        operandi of all major news outlets.</li>
                </ul>

                <h2>The process</h2>
                <p>The process of answering this question needs to be undertaken under the umbrella of a data analysis framework. This is necessary 
                    to define the steps that are required to be followed to reach an insight into the problem. Workflows have been built upon many 
                    years of data analysis work by experts in the field and to make use of that knowledge will help reach a more informed decision. 
                    By taking a standardised approach the danger of falling into a &ldquo;rabbit hole&rdquo; is lessened somewhat. This is the common 
                    occurrence of the analysis not answering the original problem and veering off at tangents. Therefore, the most important aspect 
                    is to state the aim of the analysis at the outset. All workflows begin with a business understanding step, which enforces a clear 
                    phrasing of the question that is to be answered.</p>

                <p>The Data Science process (CS109) was chosen. It is a functional work process with clearly defined goals at each step. The non-linear 
                    aspect to this process makes it the ideal candidate. As the initial question becomes better understood as we become more familiar with the data, we 
                    can skip back to previous steps and try a different modelling approach to iterate through the process to achieve a better insight.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/CS109-data-science-process.png">
                        <img src="img/project-images/good-news-project/CS109-data-science-process.png" class="figure-img img-fluid rounded" alt="CS109 data science process workflow">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> The Data Science Process &dash; CS109. Created for the Harvard data science 
                        course by Joe Blitzstein and Hanspeter Pfister &dash; <a href="http://cs109.org" target="_blank">http://cs109.org</a>
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <h2 id="ask">Ask</h2>
                <p>The question we are interested in is can news be separated into good news and bad news? More specifically:</p>

                <p><i class="fas fa-quote-left"></i> Can online news be separated into good news, that is a news story with a positive sentiment, and bad news, which 
                    is a news story with a negative sentiment? <i class="fas fa-quote-right"></i></p>

                <p>To answer this question, we must address the following challenges:</p>

                <ul>
                    <li>Can we obtain news article content?</li>
                    <li>Can we scan the article to get a sentiment score?</li>
                    <li>Can we identify good news and bad news from the sentiment score alone? Or is a more qualitative approach required?</li>
                    <li>If we can identify good news, can a model be built to predict the likelihood of a new story being good or bad?</li>
                </ul>

                <p>The answers to these challenges will answer the overall business goal: &ldquo;Is a good news website feasible or not?&rdquo;</p>

                <h3 id="good-or-bad">Good or Bad?</h3>
                <p>The immediate concern with this question is whether it is too subjective. What exactly makes a good news story? There clearly isnâ€™t a 
                    single answer to this question. The fields of psychology and political science have addressed the demand for negative news 
                    <cite><a href="#references">(Trussler & Soroka, 2014)</a></cite> and what this can do to our mental health 
                    <cite><a href="#references">(Baden, 2015)</a></cite> without identifying a taxonomy for what constitutes 
                    good and bad news. Studies that have tried to address the problem of negative news have come closer to answering this. They reveal 
                    that it is not necessarily the subject of the story that makes it good or bad, but the language used within it 
                    <cite><a href="#references">(Gyldensted, 2011)</a></cite>. A high negative word ratio and a &ldquo;victim narrative&rdquo; identify 
                    strongly as negative news stories, whereas factors such as having a higher positive word ratio (around 3:1) 
                    <cite><a href="#references">(Fredrickson & Losada, 2005)</a></cite>, having a positive message at the peak and end of a story (the peak-end 
                    rule) <cite><a href="#references">(Kahneman, et al., 1993)</a></cite>, and a meaningful narrative can identify a story as a positive one. 
                    This enforces our approach of scanning the content of the article for a sentiment score.</p>

                <h2>Get</h2>
                <p>The next stage of the process is to gather data that can help answer the question. There didnâ€™t appear to be any readily 
                    available data on news article sentiment. Most research in this area has focused on improving sentiment analysis algorithms. The current political 
                    climate has diverted attention to the 
                    <a href="https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c" target="_blank">
                    question of fake news analysis rather than sentiment analysis</a>. It became apparent therefore that the dataset would have to be created from scratch.</p>

                <h3>News Scraping</h3>
                <p>Most online news companies make available an RSS feed. This is a type of web feed which gets updated every time there is a new story. You can 
                    subscribe to the address of the feed to keep track of the news. Most news feeds return the URL of the story, from which the content can be scraped, 
                    along with other metadata such as title, summary, published date and the source. A selection of feeds was chosen to represent a broad political 
                    spectrum of the news landscape. A specific good news site was also included, the idea behind that being that it will provide some good news 
                    examples for a model to be trained with, whereas mainstream media stories might be more negative.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/news-source-ideologies.png">
                        <img src="img/project-images/good-news-project/news-source-ideologies.png" class="figure-img img-fluid rounded" alt="ideologies of online news sources">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Ideological Placement of online news sources <cite><a href="#references">(Pew Research Center, 2014)</a></cite>.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/uk-newspapers-left-or-right.png">
                        <img src="img/project-images/good-news-project/uk-newspapers-left-or-right.png" class="figure-img img-fluid rounded" alt="uk newspapers-left or right">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> How left or right wing are the mainstream UK newspapers? 
                        <a href="https://yougov.co.uk/news/2017/03/07/how-left-or-right-wing-are-uks-newspapers/" target="_blank">(yougov.co.uk)</a>.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>Based on the figures above, to represent the full political spectrum the following sources were selected:</p>

                <ul>
                    <li>The Guardian &dash; left wing</li>
                    <li>BBC News &dash; centre left</li>
                    <li>The Independent &dash; centre</li>
                    <li>The Daily Mail &dash; right wing</li>
                    <li>The Good News Network &dash; for examples of good news</li>
                    <li>Reuters</li>
                </ul>

                <p>One of the aims of the analysis from the outset was to see if good news is available, just not reported. Many online news sites 
                    get their stories from news agencies like Reuters, which is why it is included. If Reuters sentiment is higher than the other 
                    sites then we can potentially answer this question.</p>

                <h3>Sentiment Analysis</h3>
                <p>From the content a sentiment analysis score will need to be obtained. Most major cloud computing companies offer a sentiment 
                    analysis product as part of their artificial intelligence suites. Natural Language Understanding from IBM Watson was chosen as 
                    it returned more sentiment observations than any competitor, most just returned a single positive or negative score, but Watson 
                    returns additional emotions such as joy, anger, disgust, sadness, and fear. The more variables we can gather the better we can 
                    understand the problem and answer the original question. It also handles the text scraping for us, all we have to do is provide the URL.</p>

                <h3>Data Pipeline</h3>
                <p>More data isnâ€™t necessarily better. If the data is chosen in a more informative way you can get away with using smaller datasets. We 
                    have attempted to make an informed decision by selecting news feeds from across a wide range of political stand-points, but our question 
                    isnâ€™t so much concerned with which news company is more positive than another (that could make for interesting secondary analysis) but 
                    just with good news itself. Also, the lack of any existing data, and the time required to create manually, meant that some sort of automation 
                    was required to gather the data.</p>

                <p>An automated data pipeline was created using the Microsoft Azure cloud. The use of Azure Functions means that scripts can be set 
                    to run on a timer. The retrieval of news articles from the RSS feeds and retrieval of sentiment scores can be separated into their own 
                    Azure Functions and set to run at a specific time interval. A news fetch function runs once every hour and inserts new stories into a 
                    database. A sentiment analysis function then runs every five minutes, gets the next row in the database without a sentiment score, 
                    passes this to the Natural Language Understanding API and updates the database with the results. This automated pipeline means we 
                    can accumulate a large dataset with little or no extra work apart from the initial setup.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/Data_Pipeline.png">
                        <img src="img/project-images/good-news-project/Data_Pipeline.png" class="figure-img img-fluid rounded" alt="the data ingestion pipeline">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> The data ingestion pipeline. The Azure Function timings have been tweaked to strike a balance between 
                        getting sentiment scores for all articles before new ones are added and staying within the Natural Language Understanding API monthly 
                        limits for the free tier.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <h2>Explore</h2>
                <p>A combination of Python and Orange is used to explore the dataset. The structure of the dataset can be seen in the 
                    table below. Itâ€™s a good idea to review the structure at this juncture to make sure we have the data we need to answer our original 
                    question and to understand what type of problem we are trying to solve. Many data science workflows  
                    <a href="https://github.com/aakashtandel/misc_projects/blob/master/Data%20Science%20Workflow%20Project/Data%20Science%20Workflow.ipynb" target="_blank">
                    ask three questions</a> at this point to help guide the rest of the workflow:</p>

                <ul>
                    <li>Supervised or Unsupervised Learning? Supervised learning needs a target variable that is labelled so a model can learn from 
                        the existing labels to make new predictions. Techniques such as regression and classification are used here. Unsupervised learning 
                        doesnâ€™t have labels to train with. Unsupervised learning algorithms will instead look for patterns and groupings in the data 
                        using techniques such as clustering. We want to predict a good news story using sentiment and emotion scores, we donâ€™t have any 
                        labels at this point so it is an unsupervised learning problem.</li>
                    <li>Classification, Regression or Clustering? We have an unsupervised learning problem so we will have to use clustering for our initial analysis.</li>
                    <li>Prediction or Inference? We are predicting whether a news article is good news or bad news based on our sentiment and emotion features. 
                        Inference would be looking at how one feature affects an output which we are not doing.</li>
                </ul>

                <table class="table">
                    <caption><i class="fas fa-table"></i> Dataset Structure.</caption>
                    <thead>
                        <tr>
                            <th scope="col">Column</th>
                            <th scope="col">Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">Link</th>
                            <td>URL of the article</td>
                        </tr>
                        <tr>
                            <th scope="row">Title</th>
                            <td>The article headline</td>
                        </tr>
                        <tr>
                            <th scope="row">Description</th>
                            <td>A short description of the article</td>
                        </tr>
                        <tr>
                            <th scope="row">Summary</th>
                            <td>A longer paragraph summarising the article</td>
                        </tr>
                        <tr>
                            <th scope="row">Date</th>
                            <td>Date the article was published</td>
                        </tr>
                        <tr>
                            <th scope="row">Image</th>
                            <td>URL for the article banner image</td>
                        </tr>
                        <tr>
                            <th scope="row">Source</th>
                            <td>Name of the news feed that published the article</td>
                        </tr>
                        <tr>
                            <th scope="row">Sentiment</th>
                            <td>Sentiment score between -1 (negative) and 1 (positive)</td>
                        </tr>
                        <tr>
                            <th scope="row">Joy</th>
                            <td rowspan="5" style="vertical-align: middle;">A score between 0 (the article does not convey that emotion) and 1 (the 
                                article definitely conveys that emotion)</td>
                        </tr>
                        <tr>
                            <th scope="row">Anger</th>
                        </tr>
                        <tr>
                            <th scope="row">Disgust</th>
                        </tr>
                        <tr>
                            <th scope="row">Sadness</th>
                        </tr>
                        <tr>
                            <th scope="row">Fear</th>
                        </tr>
                    </tbody>
                </table>

                <h3>Data Cleaning</h3>
                <p>Even though the dataset has been created from scratch to meet our demands, real world data is messy, and there still needs to 
                    be some cleaning performed. Data types were checked and modified accordingly, the sources were categorised by company (e.g. &lsquo;World news 
                    | The Guardian&rsquo; and &lsquo;UK news | The Guardian&rsquo; both became &lsquo;The Guardian&rsquo;).</p>

                <h4>Missing Data</h4>
                <p>Missing data can affect the fit of a model or lead to a biased model because the behaviour and relationships with other variables havenâ€™t 
                    been fully analysed. This leads to incorrect predictions so itâ€™s important to check for missing data and deal with it accordingly. Itâ€™s 
                    possible that our sentiment analysis function hasnâ€™t been run on every article at the time of export. Each row without a sentiment score 
                    was therefore removed.</p>

                <h3>Exploration</h3>
                <p>Listing a general statistical summary of the dataset is a good way to start the exploration:</p>
                <table class="table">
                    <caption><i class="fas fa-table"></i> Dataset Summary.</caption>
                    <thead>
                        <tr>
                            <th scope="col"></th>
                            <th scope="col">Sentiment</th>
                            <th scope="col">Joy</th>
                            <th scope="col">Anger</th>
                            <th scope="col">Disgust</th>
                            <th scope="col">Sadness</th>
                            <th scope="col">Fear</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">Count</th>
                            <td>19661</td>
                            <td>19661</td>
                            <td>19661</td>
                            <td>19661</td>
                            <td>19661</td>
                            <td>19661</td>
                        </tr>
                        <tr>
                            <th scope="row">Mean</th>
                            <td>-0.20</td>
                            <td>0.41</td>
                            <td>0.21</td>
                            <td>0.26</td>
                            <td>0.47</td>
                            <td>0.21</td>
                        </tr>
                        <tr>
                            <th scope="row">Std</th>
                            <td>0.36</td>
                            <td>0.21</td>
                            <td>0.15</td>
                            <td>0.19</td>
                            <td>0.16</td>
                            <td>0.17</td>
                        </tr>
                        <tr>
                            <th scope="row">Min</th>
                            <td>-0.93</td>
                            <td>0.001</td>
                            <td>0.01</td>
                            <td>0.0001</td>
                            <td>0.00005</td>
                            <td>0</td>
                        </tr>
                        <tr>
                            <th scope="row">25%</th>
                            <td>-0.48</td>
                            <td>0.16</td>
                            <td>0.12</td>
                            <td>0.11</td>
                            <td>0.44</td>
                            <td>0.10</td>
                        </tr>
                        <tr>
                            <th scope="row">50%</th>
                            <td>-0.26</td>
                            <td>0.50</td>
                            <td>0.15</td>
                            <td>0.168</td>
                            <td>0.53</td>
                            <td>0.13</td>
                        </tr>
                        <tr>
                            <th scope="row">75%</th>
                            <td>0.03</td>
                            <td>0.57</td>
                            <td>0.21</td>
                            <td>0.47</td>
                            <td>0.57</td>
                            <td>0.20</td>
                        </tr>
                        <tr>
                            <th scope="row">Max</th>
                            <td>1</td>
                            <td>1</td>
                            <td>0.76</td>
                            <td>1</td>
                            <td>0.92</td>
                            <td>0.78</td>
                        </tr>
                    </tbody>
                </table>

                <p>The max and min values show that the sentiment analysis API returned valid results and there are no outliers, i.e. all values 
                    are between -1 and 1 for sentiment, and 0 and 1 for emotions.</p>
                
                <p>The mean sentiment validates our initial hypotheses that the majority of mainstream media reporting is negative, although joy 
                    seems quite high if this really is true.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/sentiment-histogram.png">
                        <img src="img/project-images/good-news-project/sentiment-histogram.png" class="figure-img img-fluid rounded" alt="sentiment histogram">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Sentiment histogram.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>Plotting a sentiment histogram confirms the hypothesis that the majority of news is negative. There is a second peak at zero which, 
                    although it is a valid value (indicating a more neutral sentiment), it was checked to make sure this wasnâ€™t as a result of the sentiment 
                    analysis returning a null value for whatever reason. The other variables all had valid values when sentiment is equal to zero so this 
                    was considered to be OK.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/scatter-plot-matrix.png">
                        <img src="img/project-images/good-news-project/scatter-plot-matrix.png" class="figure-img img-fluid rounded" alt="scatter plot matrix">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Scatter plot matrix.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>The next stage was to investigate the relationship between variableâ€™s relationships. A scatter plot matrix is a good plot to get an 
                    overall idea of this. What is striking about this plot is the groupings. It seems we have very distinct groupings of emotions, 
                    which seem to come in four different groups. Sentiment is different, we see two distinct groups. The histograms of the emotion 
                    variables (joy, anger, disgust, sadness and fear) show that emotions tend to be at one extreme or the other, with not a lot in between, 
                    hence the two distinct groupings. As sentiment becomes more positive, the negative emotions like fear, sadness, disgust and anger reduce, 
                    but the opposite happens for joy, which as a positive emotion, makes sense. The emotion histograms however seem to be telling us that our 
                    initial hypothesis about news being negative and fear mongering isnâ€™t perhaps quite the case. Fear, disgust and anger are skewed towards 
                    zero, and joy is skewed in the other direction. Sadness is the only emotion that seems to back up our hypothesis. The conclusion at this stage 
                    seems to be that although the overall sentiment of the majority of news is negative, the journalists weave a narrative, conveying the full 
                    gamut of human emotions.</p>

                <p>The distinct groupings are also intriguing in another way. We have an unsupervised learning problem and need to use clustering to analyse 
                    the data. It would appear we have obvious clustering already in the data. Can we answer our problem already without the use of a model?</p>

                <p>Plotting sentiment against joy and selecting the articles at the peak of both is our first port of call:</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/scatter-plot-sentiment-vs-joy.png">
                        <img src="img/project-images/good-news-project/scatter-plot-sentiment-vs-joy-small.png" class="figure-img img-fluid rounded" alt="scatter plot of sentiment vs joy">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Scatter plot of sentiment and joy.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>At first glance it would appear that we can simply select all articles above a certain sentiment and joy threshold and class them as 
                    good news. However, a few bad news articles were included in the selection, see the table below. For a web site devoted to good news a 
                    single bad news story finding its way onto the site would be very embarrassing, so a simple threshold check will not suffice.</p>

                <table class="table">
                    <caption><i class="fas fa-table"></i> Supposed good news articles.</caption>

                    <thead>
                        <tr>
                            <th scope="col">Title</th>
                            <th scope="col">Sentiment</th>
                            <th scope="col">Joy</th>
                            <th scope="col">Anger</th>
                            <th scope="col">Disgust</th>
                            <th scope="col">Sadness</th>
                            <th scope="col">Fear</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">
                                <small>
                                    Gold state coach journey &lsquo;horrible&rsquo; says Queen
                                </small>    
                            </th>
                            <td>0.65</td>
                            <td>0.72</td>
                            <td>0.06</td>
                            <td>0.11</td>
                            <td>0.11</td>
                            <td>0.05</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    First database of burial grounds in England and Wales to be created
                                </small>
                            </th>
                            <td>0.74</td>
                            <td>0.74</td>
                            <td>0.07</td>
                            <td>0.08</td>
                            <td>0.15</td>
                            <td>0.11</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    Eddie McConnell obituary
                                </small>
                            </th>
                            <td>0.76</td>
                            <td>0.70</td>
                            <td>0.08</td>
                            <td>0.09</td>
                            <td>0.46</td>
                            <td>0.05</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    UK falls to eighth place in Good Country Index, below Ireland
                                </small>
                            </th>
                            <td>0.83</td>
                            <td>0.75</td>
                            <td>0.06</td>
                            <td>0.04</td>
                            <td>0.16</td>
                            <td>0.06</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Clustering</h3>
                <p>The next stage was to move onto unsupervised learning. If the natural clustering and threshold check doesnâ€™t work, can an 
                    unsupervised algorithm come up with a better result? K-means clustering was used as it is a good first clustering algorithm 
                    to use in unsupervised learning and is a good way to explore the data further.</p>

                <h4>Feature Scaling</h4>
                <p>Depending on the units used to collect the data we could have a situation where we have large variance in one variable, and less 
                    in another (e.g. weights in kilos and heights in metres). A model might determine that a 1 kilo change in weight is more important, 
                    because of the size of the change from one observation to another, whereas we instinctively know that a height change of 1 metre is more 
                    important. Feature scaling is a method we can use to standardise the range of variables. Our dataset is fairly well scaled although 
                    sentiment ranges between -1 and 1, whereas the other variables range between 0 and 1. It would be better if this was standardised, 
                    especially in clustering analysis as this is based on distance measurements. The recommended standardisation is Z-score standardisation 
                    which will rescale our variables so that they have a mean of zero and a standard deviation of 1.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/k-means-clustering-with-2-clusters.png">
                        <img src="img/project-images/good-news-project/k-means-clustering-with-2-clusters-small.png" class="figure-img img-fluid rounded" alt="k-means clustering with 2 clusters">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> K-means clustering with 2 clusters.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>Only a cursory glance is required to realise that this isnâ€™t a satisfactory outcome because we already know that the majority of news 
                    articles are bad news. Even increasing the number of clusters doesnâ€™t result in a satisfactory grouping:</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <figure class="figure">
                    <a href="img/project-images/good-news-project/k-means-clustering-with-more-clusters.png">
                        <img src="img/project-images/good-news-project/k-means-clustering-with-more-clusters-small.png" class="figure-img img-fluid rounded" alt="k-means clustering with a higher number of clusters">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> K-means clustering with a higher number of clusters.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <h3>Dimensionality Reduction</h3>
                <p>Could the dataset be simplified to find more defined clusters? We have six variables in our dataset which could potentially be 
                    simplified by deriving a smaller set of variables that still explain the total variance in the dataset, but remove noise and 
                    correlated variables that are redundant. Principal Component Analysis (PCA) is one technique that can be used to do this. The image 
                    below shows the initial principal component analysis using two principal components. There doesnâ€™t appear to be a clear boundary between 
                    clusters emerging.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/pca-analysis-using-2-pcs.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/pca-analysis-using-2-pcs.png" class="figure-img img-fluid rounded" alt="pca analysis using 2 principal components">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Initial PCA analysis using 2 principal components.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>PCA extracts as many components as there are variables in the original dataset, so using more principal components may 
                    help. A scree plot (see below) visualises how many principal components explain the variance of a dataset. In higher multivariate 
                    datasets we normally see the cumulative effect tail off as we use more principal components but here we see that isnâ€™t the case. This 
                    suggests that our dataset doesnâ€™t contain noise, and we donâ€™t have any redundant variables.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/pca-scree-plot.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/pca-scree-plot.png" class="figure-img img-fluid rounded" alt="pca scree plot">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> PCA scree plot.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>It became clear at this point that unsupervised learning wasnâ€™t going to give us an answer and we would have to move onto 
                    the modelling stage of the process.</p>

                <h2>Model</h2>
                <p>Unsupervised learning, where weâ€™ve looked to algorithms to identify clustering of good news for us, hasnâ€™t resulted in a satisfactory 
                    outcome. Therefore, it is necessary to build a model ourselves. To be able to train and test a model we need to add a label to the 
                    dataset which indicates whether an article is good news or bad news. This brings us into supervised learning territory. An extra variable 
                    was added to the dataset called &lsquo;Good_News&rsquo; that is set to either yes or no. This is our &lsquo;target&rsquo; variable that we 
                    want to use a model to predict.</p>

                <p>Before a model was created, I wondered if that now we have a labelled dataset, would any clusters emerge from our PCA analysis carried out 
                    previously? Note the analysis is exactly the same, PCA is an unsupervised process, so it doesnâ€™t use any labels, this was just for a 
                    visualisation aid:</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/pca-analysis-on-the-labelled-dataset.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/pca-analysis-on-the-labelled-dataset.png" class="figure-img img-fluid rounded" alt="pca analysis on the labelled dataset">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> PCA analysis on the labelled dataset.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>The grey dots represent articles labelled as good news. We can see the beginnings of a clustering but there are too many bad 
                    news articles interspersed to be able to define a strict decision boundary.</p>

                <h3>Logistic Regression</h3>
                <p>One of the major aspects of modelling is choosing an algorithm. This becomes the baseline model which can then be tweaked (most 
                    algorithms will have parameters that can be tuned to affect the result) or even changed completely. The results of new models can 
                    then be compared to the baseline to see if an improvement has been made. Referring back to the exploration stage we described the 
                    type of problem we were trying to solve was an unsupervised clustering problem. However, now that we have a labelled dataset we can 
                    reclassify this as a supervised learning problem. Supervised learning problems can be broken down into regression problems, which deal 
                    with continuous variables, and classification problems, which are concerned with discrete variables. Our problem is therefore a 
                    classification problem, specifically a binary classification problem because we want to predict one of two possible outcomes, good 
                    news or bad news. A good first model for classification problems is logistic regression which will be looked at next.</p>

                <h4>Fit the model</h4>
                <p>Before a model can be run the dataset needs to be split into training and test sets. This allows the model to learn from labelled data 
                    and its predictions compared to a test set that it hasnâ€™t seen. This helps prevent overfitting to the model which is when the model 
                    &lsquo;follows&rsquo; the data and doesnâ€™t generalise well to new data that it hasn't seen before.</p>

                <h4>Validate the model</h4>
                <p>Once the logistic regression model was built from the training data, we use it to make predictions on the test data and compare 
                    the labels to see how accurate it is. A confusion matrix (see below) is then produced to help us visualise the performance of a 
                    classification model like logistic regression.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/logistic-regression-confusion-matrix.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/logistic-regression-confusion-matrix.png" class="figure-img img-fluid rounded" alt="logistic regression confusion matrix">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Logistic regression confusion matrix.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>The matrix can be read as follows:</p>

                <table class="table">
                    <caption><i class="fas fa-table"></i> Anatomy of a confusion matrix.</caption>
                    <thead>
                        <tr>
                            <th></th>
                            <th>Predicted No</th>
                            <th>Predicted Yes</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">Actual No</th>
                            <td class="table-success">
                                True Negatives (TN)<br>
                                Predicted No and it is No
                            </td>
                            <td class="table-danger">
                                False Positives (FP)<br>
                                Predicted Yes but it is No
                            </td>
                        </tr>
                        <tr>
                            <th scope="row">Actual Yes</th>
                            <td class="table-danger">
                                False Negatives (FN)<br>
                                Predicted No but it is Yes
                            </td>
                            <td class="table-success">
                                True Positives (TP)<br>
                                Predicted Yes and it is Yes
                            </td>
                        </tr>
                    </tbody>
                </table>

                <p>We can glean quite a lot of information from a confusion matrix:</p>

                <ul>
                    <li>Accuracy: (TP + TN) / Total = (16 + 2302) / 2341 = <span style="font-weight: bold;">0.99</span></li>
                    <li>Error Rate (how often is the model wrong?): (FP + FN) / Total = 4 + 19 / 2341 = <span style="font-weight: bold;">0.01</span></li>
                    <li>Specificity (when it is no, how often does it predict no?): TN / Actual No = 2302 / 2306 = <span style="font-weight: bold;">0.998</span></li>
                    <li>False Positive Rate (when it is no, how often does it predict yes?): FP / Actual No = 4 / 2306 = <span style="font-weight: bold;">0.002</span></li>
                    <li>True Positive Rate (when it is yes, how often does it predict yes?): TP / Actual Yes = 16 / 35 = <span style="font-weight: bold;">0.45</span></li>
                    <li>Precision (when it predicts yes, how often is it correct?): TP / Predicted Yes = 16 / 20 = <span style="font-weight: bold;">0.8</span></li>
                </ul>

                <p>Our model has an accuracy of 99%. At first glance this seems an excellent result, particularly for a baseline, but letâ€™s dig into the 
                    results further. Our bad news predictions are good. Specificity is good, so we are predicting bad news well, and the false positive rate 
                    is also good, so we are not predicting good news when it is actually bad. However, our good news prediction is not as great. The model is 
                    only predicting 45% of good news at an accuracy of 80%. There is clear room for improvement on this.</p>

                <h4>Cross-validation</h4>
                <p>With a scarcity of good news articles in the labelled dataset (around 1% of the total), maybe cross-validation can improve the accuracy 
                    of the model. This is a technique where the training set is split into <var>k</var> smaller sets, and for each of the <var>k</var> &lsquo;folds&rsquo; 
                    a model is trained using <var>k â€“ 1</var> of the folds as training data, and the resulting model is validated on the remaining part of the data held back. The 
                    final model performance measure is then the average of the values of each &lsquo;folds&rsquo;. The advantage being the entire dataset is used 
                    to train and test and each observation is used for testing exactly once. This could give the logistic regression model more visibility of 
                    good news articles and help improve the predictions.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/logistic-regression-confusion-matrix-using-xv.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/logistic-regression-confusion-matrix-using-xv.png" class="figure-img img-fluid rounded" alt="logistic regression confusion matrix using cross-validation">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Logistic regression confusion matrix using cross-validation.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>Results:</p>

                <ul>
                    <li>Accuracy: (TP + TN) / Total = (55 + 11516) / 11701 = <span style="font-weight: bold;">0.99</span></li>
                    <li>Error Rate: (FP + FN) / Total = 56 + 74 / 11701 = <span style="font-weight: bold;">0.01</span></li>
                    <li>Specificity: TN / Actual No = 11516 / 11572 = <span class="text-danger" style="font-weight: bold;">0.995</span></li>
                    <li>False Positive Rate: FP / Actual No = 56 / 11572 = <span class="text-danger" style="font-weight: bold;">0.005</span></li>
                    <li>True Positive Rate: TP / Actual Yes = 55 / 129 = <span class="text-danger" style="font-weight: bold;">0.43</span></li>
                    <li>Precision: TP / Predicted Yes = 55 / 111 = <span class="text-danger" style="font-weight: bold;">0.5</span></li>
                </ul>

                <p>Our true positive rate is slightly worse and the precision has dropped 30%! With more data being used to train the model and 
                    worse results itâ€™s clear that the model isnâ€™t good enough, itâ€™s time to look for a different technique.</p>

                <h3>Decision Tree</h3>
                <p>A decision tree creates a set of if-then-else decision rules inferred from the data features. The output being a tree which can be 
                    traversed to end up with a classification decision at the leaf nodes. The reason behind choosing this model is that we have six 
                    features with scores of which a certain combination is hoped can lead to a good news classification. Another reason is that it is 
                    an approachable model, the tree can be visualised to see what decisions have been inferred.</p>

                <p>A good first run is to limit the depth of the tree. This will give us a feel as to how the decisions are being inferred. We can see 
                    that sentiment is the main driver of the tree as it used as the parent node. Joy and anger are the other emotions considered:</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/decision-tree.svg">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/decision-tree.svg" class="figure-img img-fluid rounded" alt="decision tree visualised">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Decision tree with max depth set to three.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>Following the tree down the right-hand edge to get to the good news class gives us 219 articles of which a sample is shown in the table 
                    below. Most of the articles were good news which was encouraging, a couple of bad news articles did find their way in however, see 
                    highlighted. Maybe a deeper tree will consider the sadness emotion, which was higher for this article than the others.</p>

                <table class="table">
                    <caption><i class="fas fa-table"></i> Good news articles classified by the decision tree. (Note the larger 
                        numbers are due to the z-score standardisation function which standardises the features to have a standard 
                        deviation of 1).
                    </caption>

                    <thead>
                        <tr>
                            <th scope="col">Title</th>
                            <th scope="col">Sentiment</th>
                            <th scope="col">Joy</th>
                            <th scope="col">Anger</th>
                            <th scope="col">Disgust</th>
                            <th scope="col">Sadness</th>
                            <th scope="col">Fear</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">
                                <small>
                                    Unesco says mobile phones could wipe out the whistled language used by villagers in northern Turkey.
                                </small>
                            </th>
                            <td>2.50</td>
                            <td>1.32</td>
                            <td>-0.76</td>
                            <td>-0.88</td>
                            <td>-1.69</td>
                            <td>1.75</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    Vietnam's tech economy is experiencing an innovation renaissance, with the return of overseas nationals 
                                    injecting fresh ideas and a new energy.
                                </small>
                            </th>
                            <td>2.54</td>
                            <td>1.28</td>
                            <td>-0.65</td>
                            <td>-0.84</td>
                            <td>-2.04</td>
                            <td>-0.72</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    Neil Seviour managed to save his father's life after performing CPR he'd seen demonstrated on TV.
                                </small>
                            </th>
                            <td>2.69</td>
                            <td>1.12</td>
                            <td>-1.10</td>
                            <td>-1.12</td>
                            <td>-1.97</td>
                            <td>-0.60</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    How free courses are helping people cook cheap but nutritious meals.
                                </small>
                            </th>
                            <td>2.98</td>
                            <td>1.41</td>
                            <td>-1.02</td>
                            <td>-0.80</td>
                            <td>-2.25</td>
                            <td>-0.69</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    Why Smiling Is Good for You and Five Guaranteed Grins on World Happiness Day
                                </small>
                            </th>
                            <td>2.50</td>
                            <td>1.62</td>
                            <td>-1.07</td>
                            <td>-1.28</td>
                            <td>-0.17</td>
                            <td>-0.85</td>
                        </tr>
                        <tr class="table-danger">
                            <th scope="row">
                                <small>
                                    Job losses expected as publisher CondÃ© Nast announces UK version of title will move from monthly to twice a year
                                </small>
                            </th>
                            <td>2.43</td>
                            <td>1.25</td>
                            <td>-0.94</td>
                            <td>-1.18</td>
                            <td class="bg-danger">0.36</td>
                            <td>-0.91</td>
                        </tr>
                        <tr>
                            <th scope="row">
                                <small>
                                    Grenfell fire fundraiser shortlisted for $1m global teacher prize
                                </small>
                            </th>
                            <td>2.76</td>
                            <td>1.38</td>
                            <td>-0.51</td>
                            <td>-0.83</td>
                            <td>-1.99</td>
                            <td>-0.92</td>
                        </tr>
                    </tbody>
                </table>

                <p>Following the other paths to good news classes in the tree produced a more mixed good/bad news set of results. Rerunning the model at 
                    a deeper level to try and incorporate the other emotions into the decisions didnâ€™t result in an improvement:</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/decision-tree-confusion-matrix.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/decision-tree-confusion-matrix.png" class="figure-img img-fluid rounded" alt="decision tree confusion matrix">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Decision tree confusion matrix with a max depth of six. Compared with logistic regression 
                        this model doesnâ€™t perform any better.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <h4>Overfitting</h4>
                <p><a href="http://scikit-learn.org/stable/modules/tree.html" target="_blank">Decision trees are easy to overfit</a>. To avoid this, it 
                    is advised to perform dimensionality reduction beforehand to give the tree a better chance of finding features that are discriminative. 
                    The decision tree was rerun using the PCA dataset produced earlier in the workflow, the results can be seen below. No significant improvement 
                    is seen so overfitting isnâ€™t an issue.</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/decision-tree-confusion-matrix-using-pca-dataset.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/decision-tree-confusion-matrix-using-pca-dataset.png" class="figure-img img-fluid rounded" alt="decision tree confusion matrix using the PCA dataset">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Decision tree confusion matrix using the PCA dataset.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>As no improvement can be seen it is concluded that there arenâ€™t enough good news examples to train with. The resulting tree 
                    is therefore unbalanced and is biased towards bad news.</p>

                <h3>Random Forests</h3>
                <p>Could we take an ensemble of decision trees and get a better result? Random forest is the model to do this. This model builds a 
                    set of decision trees using an arbitrary set of features from the data, hence the term &ldquo;random&rdquo;, from which the best 
                    feature for the split is selected. The final model is based on the majority vote from individually developed trees in the forest.</p>

                <p>This model was created using Orange:</p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/random-forest-orange-workflow.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/random-forest-orange-workflow.png" class="figure-img img-fluid rounded" alt="screenshot of the random forest workflow in orange">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Random forest Orange workflow.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <a href="img/project-images/good-news-project/random-forest-confusion-matrix.png">
                <figure class="figure">
                        <img src="img/project-images/good-news-project/random-forest-confusion-matrix.png" class="figure-img img-fluid rounded" alt="random forest confusion matrix">
                    </a>
                    <figcaption class="figure-caption text-left">
                        <i class="fas fa-camera"></i> Random forest confusion matrix.
                    </figcaption>
                </figure>
            </div>
        </div>

        <div class="row">
            <div class="col-md-6">
                <p>After building and tuning three models without a discernible improvement in accuracy, it seems a good time to stop and present some conclusions.</p>

                <h2>Conclusions</h2>
                <p>To return to our original question, 	&ldquo;Can online news be separated into good news, that is a news story with a positive sentiment, and 
                    bad news, which is a news story with a negative sentiment?&rdquo;, we conclude that yes, it is possible, but with a major caveat.</p>

                <p>Our models have been accurate in predicting bad news but havenâ€™t performed well for good news articles. This shows that while a model 
                    can be built to classify articles, most good news stories will be incorrectly classified as bad news, leaving only a very small sample of good 
                    news to filter through. This is the major caveat as this means only a small supply of good news articles for the site will be available, and 
                    they will tend to be lighter in terms of content i.e. they tend to be on the trivial side of the news, as opposed to more informative news 
                    stories (see the table below for examples). In effect our models are playing &ldquo;safe&rdquo;, predicting only a tiny subset of possible 
                    good news stories. The advantage of this is that false positives are unlikely to appear on the site, which saves an embarrassing bad news 
                    article being shown.</p>

                <table class="table">
                    <caption><i class="fas fa-table"></i> Good news articles predicted by the Random Forest model. Aside from considering whether these 
                        are actually good news articles, they are not exactly hard-hitting, informative stories. The question therefore becomes, &ldquo;Would 
                        anyone want to read news stories like this?&rdquo;</caption>
                    <thead>
                        <tr>
                            <th>Title</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">Czechs consider national anthem update</th>
                            <td>Olympic Committee launches new arrangements to mark state's 100th anniversary.</td>
                        </tr>
                        <tr>
                            <th scope="row">Black Panther film: &lsquo;Game-changing&rsquo; movie takes $1bn</th>
                            <td>Analysts say the superhero film, which has a predominantly black cast, is a watershed moment.</td>
                        </tr>
                        <tr>
                            <th scope="row">Prince Harry and Meghan Markle release official engagement photos</th>
                            <td>Images were taken by the fashion and celebrity photographer Alexi Lubomirski, who says it was an incredible honour.</td>
                        </tr>
                        <tr>
                            <th scope="row">&lsquo;Lost words&rsquo; as children stay indoors</th>
                            <td>Children now spend less time outdoors and their knowledge of nature is suffering, says author Robert Macfarlane.</td>
                        </tr>
                        <tr>
                            <th scope="row">Oscars 2018: Gary Oldman on Best Actor win for Darkest Hour</th>
                            <td>The British actor thanked his mum after his Oscar win for playing Winston Churchill in Darkest Hour.</td>
                        </tr>
                        <tr>
                            <th scope="row">Egyptians gear up for Ramadan with Mo Salah lanterns</th>
                            <td>Egyptians gear up for Ramadan with Mo Salah lanterns.</td>
                        </tr>
                        <tr>
                            <th scope="row">Simon Cowell's Syco to produce its first show for the BBC</th>
                            <td>Dance talent show The Greatest Dancer is also expected to feature Cheryl and Alesha Dixon.</td>
                        </tr>
                        <tr>
                            <th scope="row">Winter Olympics: &lsquo;Taking a moment of history in their stride&rsquo; - North Korean duo shine in figure skating pairs</th>
                            <td>North Korea's only two athletes to have qualified for this year's games on merit have progressed through to Thursday's long pairs figure skating program.</td>
                        </tr>
                        <tr>
                            <th scope="row">Shopping centre Christmas trees made into rhino beds</th>
                            <td>Rhinos are sleeping on pine scented beds at Woburn Safari Park.</td>
                        </tr>
                        <tr>
                            <th scope="row">Royal engagement gets EastEnders mention</th>
                            <td>News of Prince Harry and Meghan Markle reached Albert Square.</td>
                        </tr>
                        <tr>
                            <th scope="row">More 1,000 take part in Boxing Day swims</th>
                            <td>There were beach events in Tenby and Pembrey, and a swim at the lido in Pontypridd.</td>
                        </tr>
                        <tr>
                            <th scope="row">&lsquo;If You Were Me&rsquo; TV show youngsters reunited after 48 years</th>
                            <td>The early 1970s BBC television programme &ldquo;If You Were Me&rdquo; took children on cultural exchanges around the world.</td>
                        </tr>
                    </tbody>
                </table>

                <p>The major factor in this result is that the problem domain is too subjective. Our exploration and subsequent models never produced 
                    a satisfactory decision boundary that helped to identify a good news story. This reflects the idiosyncratic nature of what constitutes 
                    a good news story which confirms our fears described in the <a href="#ask">Ask phase of the process</a>.</p>

                <h2>Going Forward</h2>
                <p>One of the biggest obstacles was a lack of balance in the training data. Modern news, as it is today, being too unbalanced in terms of 
                    good and bad news, which in turn caused our models to be biased. Given more time, more good news articles could have been collected and 
                    labelled to try and redress the balance which could have improved the accuracy.</p>

                <p>The black box approach to the sentiment and emotion scores could also have been an issue. We had no control or inkling into how Watson 
                    produced the scores. Was noise removed? i.e. advertisements, comments, links to other articles, author biographies etc. This could have 
                    affected the scores and prevented us from building an accurate model.</p>

                <p>A lot of articles in the dataset were videos. These were articles with very little text, just an accompanying video. With limited text 
                    available to get a sentiment score, the accuracy of the scores are called into question. With no way of retrieving the subtitles or 
                    captioning from the video it would have been better to have removed these from the dataset, but without an easy way to identify them, 
                    this was considered too time consuming. Other types of articles such as photo stories, satirical cartoons, and quizzes also magnified this issue.</p>

                <p>Splitting articles into categories may have helped. A positive technology story is probably different in sentiment and emotion to a positive 
                    politics story for example. Unfortunately, news feeds didnâ€™t make a category available. If it was, models could have been catered to each 
                    category to try and improve the accuracy.</p>

                <p>There was also an ethical issue at the heart of this analysis and it concerned the labelling of the supervised dataset. A model is only as 
                    good as the training data, and any biases inherent in it will emerge. I was the only person who labelled the dataset, and by extension, decided 
                    on what constituted good and bad news. A better approach would have been to get multiple people from different backgrounds and political 
                    standpoints to label the data and reach some sort of consensus.</p>

                <h2>The Good News Web Site</h2>
                <p>The data exists as a SQL Server database hosted in Azure. A .NET core application was created which uses Entity Framework Core as the data 
                    layer. Due to the lack of definitive results produced by the models, a model has not been productionised. Instead, the application simply 
                    uses threshold values to return high sentiment and positive emotion articles.</p>

                <h2>Good News 2.0</h2>
                <p>To try and rectify this issue Iâ€™m currently collecting more data and doing some feature engineering to try and create a better training 
                    set to produce a better model. Another Python script that parses the actual content of the articles has been created. This is deployed 
                    as another Azure Function that gets called when a new article is inserted into the database. It generates features such as word count, 
                    average word length, character count etc. to see if these can be used as predictors. The feature engineering involves separating quotes 
                    from the articles. The idea being that quotes from people involved in the story are better predictors of sentiment, as opposed to the 
                    journalistic language in-between which is more neutral by comparison. NLP techniques are also used in the script to &ldquo;lemmatize&rdquo; 
                    the article text. This is where variants of the same word are grouped together (e.g. plurals) to distil the text into its constituent 
                    words. From this we can analyse if it contains more positive than negative words more easily which was one of the techniques established 
                    in the <a href="#good-or-bad">Good or Bad section</a>.</p>

                <p>Alongside this work more articles are being labelled, particularly good news articles to try and balance the datasets and prevent biased 
                    results. This is currently ongoing so stay tuned for the results!</p>

                <h2 id="references">References</h2>
                <p>Baden, D., 2015. Shock! Horror! Behind the ethics and evolution of the bad news business. <cite>The Conversation,</cite> 27 March.</p>
                <p>Fredrickson, B. L. & Losada, M. F., 2005. Positive Affect and the Complex Dynamics of Human Flourishing. <cite>Am Psychol,</cite> 60(7), pp. 678-686.</p>
                <p>Gyldensted, C., 2011. <cite>Innovating News Journalism through Positive Psychology,</cite> s.l.: University of Pennsylvania.</p>
                <p>Kahneman, D., Fredrickson, B. L., Schreiber, C. A. & Redelmeier, D. A., 1993. When More Pain Is Preferred to Less: Adding a Better End. <cite>Psychological Science,</cite> 4(6), pp. 401-405.</p>
                <p>Pew Research Center, 2014. <cite>Political Polarization & Media Habits,</cite> s.l.: Pew Research Center.</p>
                <p>Trussler, M. & Soroka, S., 2014. Consumer Demand for Cynical and Negative News Frames. <cite>The Internation Journal of Press/Politics,</cite> 19(3), pp. 360-379.</p>
            </div>
        </div>
    </div>


    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
  </body>
</html>